{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# --- Configuration for Data Generation ---\n",
        "NUM_TOP_LEVEL_TASKS = 50\n",
        "MAX_SUB_LEVELS = 3 # Max depth of subtasks (e.g., Project -> Feature -> Task)\n",
        "TASKS_PER_LEVEL_RANGE = (1, 4) # Min and max subtasks per parent\n",
        "CHANCE_TO_HAVE_SUBTASKS = 0.7 # Probability a parent task will have subtasks\n",
        "CHANCE_TO_HAVE_PREDECESSOR = 0.2 # Probability a task has a predecessor\n",
        "\n",
        "\n",
        "# --- Data Value Options ---\n",
        "# Refined Project Names to sound like actual initiatives\n",
        "PROJECT_NAMES = [\n",
        "    \"Q3 Product Feature Launch - AI Integration\",\n",
        "    \"Holiday Marketing Campaign - Social Media Focus\",\n",
        "    \"Website Redesign - User Experience Overhaul\",\n",
        "    \"Internal Tool Development - Automation Suite\",\n",
        "    \"Customer Onboarding Flow Optimization\"\n",
        "]\n",
        "\n",
        "# Refined Task Types to reflect phases/roles in a workflow\n",
        "TASK_TYPES_LIST = [\n",
        "    'Strategy & Planning', 'Design & UX', 'Content Creation',\n",
        "    'Legal & Compliance Review', 'Development (Frontend)', 'Development (Backend)',\n",
        "    'QA & Testing', 'Deployment & Release', 'Marketing & Promotion',\n",
        "    'Analytics & Reporting', 'PMO & Coordination', 'Customer Support Prep'\n",
        "]\n",
        "\n",
        "\n",
        "# Assignee details (for dim_assignees) - Keep as is, they are generic enough\n",
        "ASSIGNEE_TEAMS = ['Team Alpha', 'Team Beta', 'Team Gamma', 'Team Delta']\n",
        "ASSIGNEE_NAMES_PER_TEAM = {\n",
        "    'Team Alpha': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Team Beta': ['David', 'Eve', 'Frank'],\n",
        "    'Team Gamma': ['Grace', 'Heidi', 'Ivan'],\n",
        "    'Team Delta': ['Judy', 'Karl', 'Liam']\n",
        "}\n",
        "\n",
        "ASSIGNEE_COST_PER_HOUR_RANGE = (20.0, 50.0)\n",
        "\n",
        "# Task type values (for dim_task_types) - Keep as is, values are fine\n",
        "ESTIMATED_TASK_VALUE_RANGE = (50.0, 500.0)\n",
        "\n",
        "# Status options - Keep as is, these are standard\n",
        "STATUS_OPTIONS = ['To Do', 'In Progress', 'Blocked', 'Review', 'Completed']\n",
        "PRIORITY_OPTIONS = ['Critical', 'High', 'Medium', 'Low']\n",
        "\n",
        "# Refined Blocker Reasons to be more specific to workflows\n",
        "BLOCKER_REASONS = [\n",
        "    'Awaiting Client Feedback', 'Resource Unavailability', 'Unexpected Scope Creep',\n",
        "    'Technical Bug Found', 'External API Dependency', 'Legal Review Pending',\n",
        "    'Design Approval Needed', 'Cross-Team Handoff Delay', 'Data Access Issues'\n",
        "]\n",
        "QUALITY_REVIEW_STATUS_OPTIONS = ['Passed', 'Minor Rework', 'Major Rework', 'Failed QA']\n",
        "\n",
        "\n",
        "# --- Messiness Configuration (for Version A) - Keep as is, these rates are good\n",
        "MISSING_VALUE_RATES = {\n",
        "    'due_date': 0.15,\n",
        "    'time_tracked_hours': 0.20,\n",
        "    'blocker_reason': 0.70,\n",
        "    'date_completed': 0.05,\n",
        "    'percentage_completion': 0.10\n",
        "}\n",
        "INCONSISTENT_SPELLING_RATES = {\n",
        "    'status': 0.25,\n",
        "    'blocker_reason': 0.30,\n",
        "    'priority': 0.15\n",
        "}\n",
        "ILLOGICAL_DATA_RATES = {\n",
        "    'completed_but_not_100_percent': 0.05,\n",
        "    'in_progress_but_100_percent': 0.03,\n",
        "    'completed_before_created': 0.02,\n",
        "    'overdue_but_not_blocked': 0.05\n",
        "}\n",
        "\n",
        "\n",
        "# --- Update the task_name generation logic in generate_task_data function ---\n",
        "# This part is inside the generate_task_data function, not in the config block\n",
        "# Original: 'task_name': f\"Task {task_id} - {random.choice(['Feature', 'Bug Fix', 'Report', 'Analysis', 'Meeting Prep'])}\",\n",
        "# New:\n",
        "TASK_NAME_SUFFIXES = {\n",
        "    'Strategy & Planning': ['Define Objectives', 'Market Research', 'Budget Allocation'],\n",
        "    'Design & UX': ['Wireframe Creation', 'Mockup Design', 'User Testing'],\n",
        "    'Content Creation': ['Ad Copy Draft', 'Social Media Post', 'Blog Article'],\n",
        "    'Legal & Compliance Review': ['Review Ad Copy', 'Compliance Check', 'Contract Approval'],\n",
        "    'Development (Frontend)': ['Build UI Component', 'Integrate API', 'Frontend Bug Fix'],\n",
        "    'Development (Backend)': ['Database Schema Update', 'API Endpoint Creation', 'Performance Tuning'],\n",
        "    'QA & Testing': ['Unit Testing', 'Integration Testing', 'UAT Coordination'],\n",
        "    'Deployment & Release': ['Release Plan', 'Deployment Script', 'Post-Launch Monitoring Setup'],\n",
        "    'Marketing & Promotion': ['Campaign Launch', 'Ad Spend Optimization', 'Performance Tracking'],\n",
        "    'Analytics & Reporting': ['Data Collection Setup', 'Dashboard Build', 'Performance Report'],\n",
        "    'PMO & Coordination': ['Stakeholder Sync', 'Risk Assessment', 'Dependency Management'],\n",
        "    'Customer Support Prep': ['FAQ Document', 'Training Material', 'Support Handoff']\n",
        "}\n",
        "\n",
        "\n",
        "# --- Helper Functions for Data Generation ---\n",
        "\n",
        "def generate_assignees_dim():\n",
        "    \"\"\"Generates the dim_assignees DataFrame.\"\"\"\n",
        "    assignees_data = []\n",
        "    assignee_id_counter = 1\n",
        "    for team in ASSIGNEE_TEAMS:\n",
        "        for name in ASSIGNEE_NAMES_PER_TEAM[team]:\n",
        "            assignee_id = f\"ASS-{assignee_id_counter:03d}\"\n",
        "            assignee_id_counter += 1\n",
        "            assignees_data.append({\n",
        "                'assignee_id': assignee_id,\n",
        "                'assignee_name': name,\n",
        "                'assignee_team': team,\n",
        "                'assignee_cost_per_hour': round(random.uniform(*ASSIGNEE_COST_PER_HOUR_RANGE), 2)\n",
        "            })\n",
        "    return pd.DataFrame(assignees_data)\n",
        "\n",
        "def generate_task_types_dim():\n",
        "    \"\"\"Generates the dim_task_types DataFrame.\"\"\"\n",
        "    task_types_data = []\n",
        "    for task_type_name in TASK_TYPES_LIST:\n",
        "        task_types_data.append({\n",
        "            'task_type_id': task_type_name, # Using name as ID for simplicity\n",
        "            'task_type_name': task_type_name,\n",
        "            'estimated_task_value': round(random.uniform(*ESTIMATED_TASK_VALUE_RANGE), 2)\n",
        "        })\n",
        "    return pd.DataFrame(task_types_data)\n",
        "\n",
        "def generate_task_data(\n",
        "    parent_id=None,\n",
        "    level=1,\n",
        "    existing_task_ids=None,\n",
        "    assignees_df=None,\n",
        "    task_types_df=None\n",
        "):\n",
        "    \"\"\"Recursively generates a single task and its subtasks.\"\"\"\n",
        "    global task_id_counter\n",
        "    task_id = f\"T-{task_id_counter:05d}\"\n",
        "    task_id_counter += 1\n",
        "\n",
        "    # Ensure existing_task_ids is a list\n",
        "    if existing_task_ids is None:\n",
        "        existing_task_ids = []\n",
        "\n",
        "    # Select random assignee and task type from dimensions\n",
        "    assignee_info = assignees_df.sample(1).iloc[0]\n",
        "    assignee_id = assignee_info['assignee_id']\n",
        "\n",
        "    task_type_info = task_types_df.sample(1).iloc[0]\n",
        "    task_type = task_type_info['task_type_id']\n",
        "\n",
        "    # Dates\n",
        "    base_date = datetime.now() - timedelta(days=random.randint(90, 365)) # Tasks up to a year old\n",
        "    date_created = base_date + timedelta(days=random.randint(0, 30))\n",
        "    start_date = date_created + timedelta(days=random.randint(0, 7))\n",
        "    due_date = start_date + timedelta(days=random.randint(5, 60)) # Due 5 to 60 days after start\n",
        "\n",
        "    status = random.choice(STATUS_OPTIONS)\n",
        "    percentage_completion = 0.0\n",
        "    time_tracked_hours = 0.0\n",
        "    date_completed = None\n",
        "\n",
        "    if status == 'Completed':\n",
        "        percentage_completion = 100.0\n",
        "        # Completed date is usually on or before due date, but can be slightly after\n",
        "        date_completed = due_date - timedelta(days=random.randint(-10, 5))\n",
        "        time_tracked_hours = round(random.uniform(5.0, 40.0), 1)\n",
        "    elif status == 'In Progress':\n",
        "        percentage_completion = round(random.uniform(10.0, 90.0), 1)\n",
        "        time_tracked_hours = round(random.uniform(1.0, 25.0), 1)\n",
        "    elif status == 'Review':\n",
        "        percentage_completion = 100.0 # Typically 100% for review\n",
        "        time_tracked_hours = round(random.uniform(5.0, 35.0), 1)\n",
        "        # Review tasks might have a completed date (initial work done) or not yet\n",
        "        if random.random() < 0.7:\n",
        "             date_completed = due_date - timedelta(days=random.randint(-10, 5))\n",
        "    elif status == 'Blocked':\n",
        "        percentage_completion = round(random.uniform(0.0, 80.0), 1)\n",
        "        time_tracked_hours = round(random.uniform(0.0, 15.0), 1)\n",
        "        # Blocked tasks might have a due date in the future, or already passed\n",
        "        due_date = due_date + timedelta(days=random.randint(0, 30)) # Push due date out if blocked\n",
        "    else: # To Do\n",
        "        percentage_completion = 0.0\n",
        "        time_tracked_hours = 0.0\n",
        "\n",
        "    blocker_reason = random.choice(BLOCKER_REASONS) if status == 'Blocked' else None\n",
        "    quality_review_status = None\n",
        "    if status in ['Completed', 'Review'] and random.random() < 0.4: # 40% chance of review status\n",
        "        quality_review_status = random.choice(QUALITY_REVIEW_STATUS_OPTIONS)\n",
        "\n",
        "    last_updated_date = datetime.now() - timedelta(days=random.randint(0, 14)) # Last updated recently\n",
        "\n",
        "    # Predecessor Task ID\n",
        "    predecessor_task_id = None\n",
        "    if level > 1 and len(existing_task_ids) > 5 and random.random() < CHANCE_TO_HAVE_PREDECESSOR:\n",
        "        # Pick a random existing task that is not this task itself\n",
        "        predecessor_task_id = random.choice([tid for tid in existing_task_ids if tid != task_id])\n",
        "\n",
        "    # --- CORRECTED TASK NAME GENERATION ---\n",
        "    task_name_suffix_options = TASK_NAME_SUFFIXES.get(task_type, ['Generic Task']) # Fallback\n",
        "    task_name = f\"{random.choice(task_name_suffix_options)} - {task_id}\"\n",
        "    # --- END CORRECTED TASK NAME GENERATION ---\n",
        "\n",
        "    task_data = {\n",
        "        'task_id': task_id,\n",
        "        'parent_id': parent_id,\n",
        "        'project_name': random.choice(PROJECT_NAMES),\n",
        "        'task_name': task_name, # Use the newly generated realistic task name\n",
        "        'status': status,\n",
        "        'percentage_completion': percentage_completion,\n",
        "        'date_created': date_created,\n",
        "        'start_date': start_date,\n",
        "        'due_date': due_date,\n",
        "        'date_completed': date_completed,\n",
        "        'time_tracked_hours': time_tracked_hours,\n",
        "        'task_type': task_type,\n",
        "        'complexity_points': random.randint(1, 5),\n",
        "        'priority': random.choice(PRIORITY_OPTIONS),\n",
        "        'blocker_reason': blocker_reason,\n",
        "        'quality_review_status': quality_review_status,\n",
        "        'last_updated_date': last_updated_date,\n",
        "        'predecessor_task_id': predecessor_task_id,\n",
        "        'assignee_id': assignee_id\n",
        "    }\n",
        "\n",
        "    all_tasks_data.append(task_data)\n",
        "    existing_task_ids.append(task_id) # Add current task to list for future predecessors\n",
        "\n",
        "    # Generate subtasks\n",
        "    if level < MAX_SUB_LEVELS and random.random() < CHANCE_TO_HAVE_SUBTASKS:\n",
        "        num_children = random.randint(*TASKS_PER_LEVEL_RANGE)\n",
        "        for _ in range(num_children):\n",
        "            generate_task_data(task_id, level + 1, existing_task_ids, assignees_df, task_types_df)\n",
        "\n",
        "\n",
        "# --- Functions to Introduce Messiness ---\n",
        "\n",
        "def introduce_missing_values(df, rates):\n",
        "    \"\"\"Introduces NaN values based on specified rates.\"\"\"\n",
        "    df_messy = df.copy()\n",
        "    for col, rate in rates.items():\n",
        "        if col in df_messy.columns:\n",
        "            mask = np.random.rand(len(df_messy)) < rate\n",
        "            df_messy.loc[mask, col] = np.nan\n",
        "    return df_messy\n",
        "\n",
        "def introduce_inconsistent_spellings(df, col_rates_map):\n",
        "    \"\"\"Introduces inconsistent spellings for categorical columns.\"\"\"\n",
        "    df_messy = df.copy()\n",
        "    for col, rate in col_rates_map.items():\n",
        "        if col in df_messy.columns:\n",
        "            unique_values = df_messy[col].dropna().unique()\n",
        "            if len(unique_values) > 0:\n",
        "                for val in unique_values:\n",
        "                    mask = (df_messy[col] == val) & (np.random.rand(len(df_messy)) < rate)\n",
        "                    if col == 'status':\n",
        "                        if val == 'To Do': df_messy.loc[mask, col] = random.choice(['todo', 'TO DO', 'To-Do'])\n",
        "                        elif val == 'In Progress': df_messy.loc[mask, col] = random.choice(['in progress', 'Inprogress', 'IN PROGRESS'])\n",
        "                        elif val == 'Completed': df_messy.loc[mask, col] = random.choice(['Done', 'completed.', 'COMPLETED'])\n",
        "                        elif val == 'Blocked': df_messy.loc[mask, col] = random.choice(['blocked!', 'BLOCKED'])\n",
        "                        elif val == 'Review': df_messy.loc[mask, col] = random.choice(['review', 'REVIEW'])\n",
        "                    elif col == 'blocker_reason':\n",
        "                        df_messy.loc[mask, col] = random.choice([val.lower(), val.upper(), val.replace(' ', ''), val + '!'])\n",
        "                    elif col == 'priority':\n",
        "                        if val == 'Critical': df_messy.loc[mask, col] = random.choice(['critical', 'CRITICAL'])\n",
        "                        elif val == 'High': df_messy.loc[mask, col] = random.choice(['high', 'HIGH'])\n",
        "                        elif val == 'Medium': df_messy.loc[mask, col] = random.choice(['medium', 'MED'])\n",
        "                        elif val == 'Low': df_messy.loc[mask, col] = random.choice(['low', 'LOW'])\n",
        "    return df_messy\n",
        "\n",
        "def introduce_illogical_data(df):\n",
        "    \"\"\"Introduces illogical data points.\"\"\"\n",
        "    df_messy = df.copy()\n",
        "\n",
        "    # Ensure date columns are datetime objects for consistency before operations\n",
        "    # Use errors='coerce' to turn unparseable dates into NaT (Not a Time)\n",
        "    df_messy['date_created'] = pd.to_datetime(df_messy['date_created'], errors='coerce')\n",
        "    df_messy['date_completed'] = pd.to_datetime(df_messy['date_completed'], errors='coerce')\n",
        "    df_messy['due_date'] = pd.to_datetime(df_messy['due_date'], errors='coerce')\n",
        "    df_messy['last_updated_date'] = pd.to_datetime(df_messy['last_updated_date'], errors='coerce')\n",
        "\n",
        "\n",
        "    # Completed but not 100%\n",
        "    mask = (df_messy['status'] == 'Completed') & (np.random.rand(len(df_messy)) < ILLOGICAL_DATA_RATES['completed_but_not_100_percent'])\n",
        "    df_messy.loc[mask, 'percentage_completion'] = round(random.uniform(50.0, 99.9), 1)\n",
        "\n",
        "    # In Progress but 100%\n",
        "    mask = (df_messy['status'] == 'In Progress') & (np.random.rand(len(df_messy)) < ILLOGICAL_DATA_RATES['in_progress_but_100_percent'])\n",
        "    df_messy.loc[mask, 'percentage_completion'] = 100.0\n",
        "\n",
        "    # Completed date before created date\n",
        "    mask = (df_messy['status'] == 'Completed') & (np.random.rand(len(df_messy)) < ILLOGICAL_DATA_RATES['completed_before_created'])\n",
        "    # Ensure date_created and date_completed are not NaT before comparison\n",
        "    valid_dates_mask = df_messy['date_created'].notna() & df_messy['date_completed'].notna()\n",
        "    df_messy.loc[mask & valid_dates_mask, 'date_completed'] = df_messy.loc[mask & valid_dates_mask, 'date_created'] - timedelta(days=random.randint(1, 30))\n",
        "\n",
        "    # Overdue but no blocker reason (if status is Blocked and due date passed)\n",
        "    # Ensure date columns are datetime objects for comparison (already done at start of function)\n",
        "    overdue_blocked_mask = (df_messy['status'] == 'Blocked') & \\\n",
        "                           (df_messy['due_date'].notna()) & \\\n",
        "                           (df_messy['last_updated_date'].notna()) & \\\n",
        "                           (df_messy['due_date'] < df_messy['last_updated_date'])\n",
        "\n",
        "    # Then, for a subset of these, remove the blocker reason\n",
        "    mask_to_remove_blocker = overdue_blocked_mask & (np.random.rand(len(df_messy)) < ILLOGICAL_DATA_RATES['overdue_but_not_blocked'])\n",
        "    df_messy.loc[mask_to_remove_blocker, 'blocker_reason'] = np.nan\n",
        "\n",
        "    return df_messy\n",
        "\n",
        "\n",
        "# --- Main Generation Process ---\n",
        "\n",
        "# 1. Generate Dimension Tables\n",
        "assignees_df = generate_assignees_dim()\n",
        "task_types_df = generate_task_types_dim()\n",
        "\n",
        "# 2. Generate Clean ClickUp Tasks Data\n",
        "task_id_counter = 1\n",
        "all_tasks_data = []\n",
        "existing_task_ids = [] # To keep track of IDs for predecessor assignments\n",
        "\n",
        "print(\"Generating clean dummy data...\")\n",
        "for _ in range(NUM_TOP_LEVEL_TASKS):\n",
        "    generate_task_data(\n",
        "        assignees_df=assignees_df,\n",
        "        task_types_df=task_types_df,\n",
        "        existing_task_ids=existing_task_ids # Pass the list by reference\n",
        "    )\n",
        "\n",
        "df_clean = pd.DataFrame(all_tasks_data)\n",
        "\n",
        "# Convert dates to string format for CSV export (or keep as datetime for direct analysis)\n",
        "# NOTE: This conversion happens *after* df_clean is created and before df_messy is derived.\n",
        "# The introduce_illogical_data function now handles its own datetime conversion.\n",
        "df_clean['date_created'] = df_clean['date_created'].dt.strftime('%Y-%m-%d')\n",
        "df_clean['start_date'] = df_clean['start_date'].dt.strftime('%Y-%m-%d').fillna('')\n",
        "df_clean['due_date'] = df_clean['due_date'].dt.strftime('%Y-%m-%d').fillna('')\n",
        "df_clean['date_completed'] = df_clean['date_completed'].dt.strftime('%Y-%m-%d').fillna('')\n",
        "df_clean['last_updated_date'] = df_clean['last_updated_date'].dt.strftime('%Y-%m-%d').fillna('')\n",
        "\n",
        "\n",
        "# 3. Introduce Messiness for Version A\n",
        "print(\"Introducing messiness for Version A...\")\n",
        "df_messy = df_clean.copy()\n",
        "\n",
        "# Introduce missing values\n",
        "df_messy = introduce_missing_values(df_messy, MISSING_VALUE_RATES)\n",
        "\n",
        "# Introduce inconsistent spellings\n",
        "df_messy = introduce_inconsistent_spellings(df_messy, INCONSISTENT_SPELLING_RATES)\n",
        "\n",
        "# Introduce illogical data\n",
        "df_messy = introduce_illogical_data(df_messy)\n",
        "\n",
        "# Ensure 'parent_id' and 'predecessor_task_id' are string type for consistency,\n",
        "# and replace NaN with empty string for CSV export if needed.\n",
        "df_messy['parent_id'] = df_messy['parent_id'].fillna('').astype(str)\n",
        "df_messy['predecessor_task_id'] = df_messy['predecessor_task_id'].fillna('').astype(str)\n",
        "df_clean['parent_id'] = df_clean['parent_id'].fillna('').astype(str)\n",
        "df_clean['predecessor_task_id'] = df_clean['predecessor_task_id'].fillna('').astype(str)\n",
        "\n",
        "\n",
        "# --- Save to CSV Files ---\n",
        "output_dir = './' # You can change this to a specific directory if needed\n",
        "\n",
        "# Save dimension tables (clean)\n",
        "assignees_df.to_csv(f'{output_dir}dim_assignees.csv', index=False)\n",
        "task_types_df.to_csv(f'{output_dir}dim_task_types.csv', index=False)\n",
        "\n",
        "# Save messy clickup tasks data (Version A)\n",
        "df_messy.to_csv(f'{output_dir}dummy_clickup_tasks_messy.csv', index=False)\n",
        "\n",
        "# NEW: Save clean clickup tasks data (Version B)\n",
        "df_clean.to_csv(f'{output_dir}dummy_clickup_tasks_clean.csv', index=False)\n",
        "\n",
        "\n",
        "print(\"\\n--- Generation Complete ---\")\n",
        "print(f\"Generated {len(df_messy)} messy tasks in 'dummy_clickup_tasks_messy.csv'\")\n",
        "print(f\"Generated {len(df_clean)} clean tasks in 'dummy_clickup_tasks_clean.csv'\") # Added clean count\n",
        "print(f\"Generated {len(assignees_df)} assignees in 'dim_assignees.csv'\")\n",
        "print(f\"Generated {len(task_types_df)} task types in 'dim_task_types.csv'\")\n",
        "\n",
        "print(\"\\nFirst 10 rows of MESSY data:\")\n",
        "print(df_messy.head(10))\n",
        "\n",
        "print(\"\\nMessy Data Info (check for NaNs and data types):\")\n",
        "print(df_messy.info())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating clean dummy data...\n",
            "Introducing messiness for Version A...\n",
            "\n",
            "--- Generation Complete ---\n",
            "Generated 273 messy tasks in 'dummy_clickup_tasks_messy.csv'\n",
            "Generated 273 clean tasks in 'dummy_clickup_tasks_clean.csv'\n",
            "Generated 12 assignees in 'dim_assignees.csv'\n",
            "Generated 12 task types in 'dim_task_types.csv'\n",
            "\n",
            "First 10 rows of MESSY data:\n",
            "   task_id parent_id                                     project_name  \\\n",
            "0  T-00001            Holiday Marketing Campaign - Social Media Focus   \n",
            "1  T-00002   T-00001            Customer Onboarding Flow Optimization   \n",
            "2  T-00003                 Q3 Product Feature Launch - AI Integration   \n",
            "3  T-00004   T-00003            Customer Onboarding Flow Optimization   \n",
            "4  T-00005   T-00004       Q3 Product Feature Launch - AI Integration   \n",
            "5  T-00006   T-00003       Q3 Product Feature Launch - AI Integration   \n",
            "6  T-00007   T-00006            Customer Onboarding Flow Optimization   \n",
            "7  T-00008   T-00006     Internal Tool Development - Automation Suite   \n",
            "8  T-00009   T-00006  Holiday Marketing Campaign - Social Media Focus   \n",
            "9  T-00010            Holiday Marketing Campaign - Social Media Focus   \n",
            "\n",
            "                          task_name      status  percentage_completion  \\\n",
            "0       Deployment Script - T-00001        todo                    NaN   \n",
            "1   Data Collection Setup - T-00002      Review                    NaN   \n",
            "2      Performance Report - T-00003      Review                  100.0   \n",
            "3      Wireframe Creation - T-00004       To Do                    0.0   \n",
            "4     Integration Testing - T-00005       To Do                    0.0   \n",
            "5  Database Schema Update - T-00006   Completed                  100.0   \n",
            "6        Frontend Bug Fix - T-00007  completed.                  100.0   \n",
            "7            User Testing - T-00008      REVIEW                  100.0   \n",
            "8        Compliance Check - T-00009       To Do                    0.0   \n",
            "9      Performance Report - T-00010       To Do                    0.0   \n",
            "\n",
            "  date_created  start_date   due_date date_completed  time_tracked_hours  \\\n",
            "0   2024-09-12  2024-09-18 2024-10-14            NaT                 NaN   \n",
            "1   2024-07-19  2024-07-24 2024-08-23     2024-08-21                11.6   \n",
            "2   2024-11-13  2024-11-13 2024-11-24     2024-11-27                32.6   \n",
            "3   2025-03-06  2025-03-07 2025-04-20            NaT                 0.0   \n",
            "4   2024-08-08  2024-08-08 2024-08-28            NaT                 NaN   \n",
            "5   2024-09-29  2024-10-04 2024-11-23     2024-11-26                 NaN   \n",
            "6   2025-03-04  2025-03-05 2025-03-22     2025-03-18                 5.5   \n",
            "7   2024-12-01  2024-12-04 2025-01-22     2025-01-17                12.4   \n",
            "8   2024-12-16  2024-12-16 2025-01-11            NaT                 NaN   \n",
            "9   2025-02-28  2025-03-06 2025-04-03            NaT                 0.0   \n",
            "\n",
            "                   task_type  complexity_points  priority blocker_reason  \\\n",
            "0       Deployment & Release                  3      High            NaN   \n",
            "1      Analytics & Reporting                  1       Low            NaN   \n",
            "2      Analytics & Reporting                  3  Critical           None   \n",
            "3                Design & UX                  2  Critical           None   \n",
            "4               QA & Testing                  5       Low            NaN   \n",
            "5      Development (Backend)                  1       Low            NaN   \n",
            "6     Development (Frontend)                  5      High           None   \n",
            "7                Design & UX                  1      High            NaN   \n",
            "8  Legal & Compliance Review                  3       low            NaN   \n",
            "9      Analytics & Reporting                  2    Medium            NaN   \n",
            "\n",
            "  quality_review_status last_updated_date predecessor_task_id assignee_id  \n",
            "0                  None        2025-07-02                         ASS-006  \n",
            "1                  None        2025-07-02                         ASS-009  \n",
            "2                  None        2025-07-04                         ASS-012  \n",
            "3                  None        2025-07-03                         ASS-006  \n",
            "4                  None        2025-06-29                         ASS-011  \n",
            "5          Major Rework        2025-07-03                         ASS-011  \n",
            "6                  None        2025-07-06             T-00002     ASS-011  \n",
            "7          Minor Rework        2025-06-23                         ASS-012  \n",
            "8                  None        2025-06-28                         ASS-008  \n",
            "9                  None        2025-07-05                         ASS-004  \n",
            "\n",
            "Messy Data Info (check for NaNs and data types):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 273 entries, 0 to 272\n",
            "Data columns (total 19 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   task_id                273 non-null    object        \n",
            " 1   parent_id              273 non-null    object        \n",
            " 2   project_name           273 non-null    object        \n",
            " 3   task_name              273 non-null    object        \n",
            " 4   status                 273 non-null    object        \n",
            " 5   percentage_completion  245 non-null    float64       \n",
            " 6   date_created           273 non-null    datetime64[ns]\n",
            " 7   start_date             273 non-null    object        \n",
            " 8   due_date               235 non-null    datetime64[ns]\n",
            " 9   date_completed         86 non-null     datetime64[ns]\n",
            " 10  time_tracked_hours     220 non-null    float64       \n",
            " 11  task_type              273 non-null    object        \n",
            " 12  complexity_points      273 non-null    int64         \n",
            " 13  priority               273 non-null    object        \n",
            " 14  blocker_reason         15 non-null     object        \n",
            " 15  quality_review_status  39 non-null     object        \n",
            " 16  last_updated_date      273 non-null    datetime64[ns]\n",
            " 17  predecessor_task_id    273 non-null    object        \n",
            " 18  assignee_id            273 non-null    object        \n",
            "dtypes: datetime64[ns](4), float64(2), int64(1), object(12)\n",
            "memory usage: 40.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLcaB7oJXFXu",
        "outputId": "a476a877-103e-468d-e922-4eac1628274b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}